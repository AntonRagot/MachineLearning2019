{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tX.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some constants\n",
    "\n",
    "M = X.shape[1] # number of features\n",
    "UNDEF = -999.\n",
    "JET_NUM_INDEX = 22 # the index of the PRI_jet_num feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group data by PRI_jet_num\n",
    "def separate_data(X, y, val):\n",
    "    mask = X[:, JET_NUM_INDEX] == val\n",
    "    return X[mask], y[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows that still have undefined values\n",
    "def remove_undef_rows(X,y,info=False):\n",
    "    to_remove = []\n",
    "    for i,row in enumerate(X):\n",
    "        if UNDEF in row:\n",
    "            to_remove.append(i)\n",
    "    x_clean = np.delete(X, to_remove, axis=0)\n",
    "    y_clean = np.delete(y, to_remove)\n",
    "    if info:\n",
    "        print('Removed',len(to_remove),'samples containing',UNDEF)\n",
    "    return x_clean, y_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute weights for columns we selected\n",
    "def regress(X, y, mask):\n",
    "    x_masked = np.take(X, mask, axis=1)\n",
    "    x_clean, y_clean = remove_undef_rows(x_masked, y)\n",
    "    w,_ = least_squares(y_clean, x_clean)\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put 0 weights where the removed columns are, so we can simply multiply with test set without removing columns again\n",
    "def rescale(w, mask, M=M):\n",
    "    out = np.zeros((M,))\n",
    "    for e,i in enumerate(mask):\n",
    "        out[i] = w[e]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(ws, X):\n",
    "    labels = []\n",
    "    for sample in X:\n",
    "        labels.append(sample @ ws[int(sample[22])])\n",
    "    labels = np.array(labels)\n",
    "    labels[labels > 0] = 1\n",
    "    labels[labels <= 0] = -1\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, actual):\n",
    "    return np.sum(predictions==actual)/len(actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose relevant columns for each group\n",
    "mask0 = [0,1,2,3,7,10,11,13,14,15,16,17,18,19,20,21]\n",
    "mask1 = [0,1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,23,24,25,29]\n",
    "mask2 = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29]\n",
    "mask3 = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,23,24,25,26,27,28,29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 726,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, test_x, test_y = split_data(X, y, 0.1) # split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 727,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0, y0 = separate_data(train_x, train_y, 0)\n",
    "x1, y1 = separate_data(train_x, train_y, 1)\n",
    "x2, y2 = separate_data(train_x, train_y, 2)\n",
    "x3, y3 = separate_data(train_x, train_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 728,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = rescale(regress(x0,y0,mask0), mask0)\n",
    "w1 = rescale(regress(x1,y1,mask1), mask1)\n",
    "w2 = rescale(regress(x2,y2,mask2), mask2)\n",
    "w3 = rescale(regress(x3,y3,mask3), mask3)\n",
    "ws = [w0,w1,w2,w3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 225000 test samples is 0.7529644444444444\n"
     ]
    }
   ],
   "source": [
    "# check accuracy on our test set\n",
    "predictions = predict(ws, test_x)\n",
    "print('Accuracy on',len(test_y),'test samples is',accuracy(predictions,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train samples is 0.75168\n"
     ]
    }
   ],
   "source": [
    "# check accuracy on our train set\n",
    "predictions_0 = predict(ws, train_x)\n",
    "print('Accuracy on train samples is',accuracy(predictions_0,train_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "misclassified = predictions != test_y\n",
    "vals = test_x[misclassified]\n",
    "correct = test_x[predictions == test_y]\n",
    "\n",
    "errors = np.array([np.sum(vals[:,22] == 0), np.sum(vals[:,22] == 1),np.sum(vals[:,22] == 2),np.sum(vals[:,22] == 3)])\n",
    "total_in_group = np.array([np.sum(test_x[:,22]==0),np.sum(test_x[:,22]==1),np.sum(test_x[:,22]==2),np.sum(test_x[:,22]==3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.04029711, 30.4902003 , 27.66871571, 27.76662988])"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "errors / total_in_group * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = '../data/test.csv'\n",
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_PATH = '../output/predictions_2.csv'\n",
    "y_pred = predict(ws, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unused stuff, keep it here just in case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_undefined_with_mean(X, wrong_value):\n",
    "    def nan_if(x, wrong_value):\n",
    "        return np.where(X == wrong_value, np.nan, X)\n",
    "\n",
    "    means = np.nanmean(nan_if(X, wrong_value), axis=0)\n",
    "\n",
    "    X_clean = np.zeros(X.shape)\n",
    "    for i,row in enumerate(X):\n",
    "        mask = row == wrong_value\n",
    "        X_clean[i] = mask*means + np.logical_not(mask)*row\n",
    "    return X_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data(X):\n",
    "    return (X - np.mean(X, axis=0)) / np.std(X, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accs = []\n",
    "for i in range(100):\n",
    "    train_x, train_y, test_x, test_y = split_data(X, y, 0.6, seed=i) # split into train and test\n",
    "    x0, y0 = separate_data(train_x, train_y, 0)\n",
    "    x1, y1 = separate_data(train_x, train_y, 1)\n",
    "    x2, y2 = separate_data(train_x, train_y, 2)\n",
    "    x3, y3 = separate_data(train_x, train_y, 3)\n",
    "    w0 = rescale(regress(x0,y0,mask0), mask0)\n",
    "    w1 = rescale(regress(x1,y1,mask1), mask1)\n",
    "    w2 = rescale(regress(x2,y2,mask2), mask2)\n",
    "    w3 = rescale(regress(x3,y3,mask3), mask3)\n",
    "    ws = [w0,w1,w2,w3]\n",
    "    predictions = predict(ws, test_x)\n",
    "    accs.append(accuracy(predictions, test_y))\n",
    "    print('\\r%d' % i,end='')\n",
    "np.argmax(accs)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
