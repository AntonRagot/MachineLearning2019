{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path, test=False):\n",
    "    lines = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        lines = [l.strip() for l in lines]\n",
    "    if test:\n",
    "        ids = [l.split(',')[0] for l in lines]\n",
    "        return ids, lines\n",
    "    else:\n",
    "        return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# should we remove dulicates or nah ?\n",
    "pos = list(set(load_data('data/train_pos_full.txt')))\n",
    "neg = list(set(load_data('data/train_neg_full.txt')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### /!\\ faire du data preprocessing ici"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# besoin de ça pour train le naive bayes classifier\n",
    "def extract_features(word_list):\n",
    "    return dict([(word, True) for word in word_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_features = [(extract_features(l.split()),'1') for l in pos]\n",
    "neg_features = [(extract_features(l.split()),'-1') for l in neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on garde un peu de test set pour verifier\n",
    "threshold_factor = 0.8\n",
    "pos_thresh = int(threshold_factor * len(pos_features))\n",
    "neg_thresh = int(threshold_factor * len(neg_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training datapoints: 2270482\n",
      "Number of test datapoints: 454097\n"
     ]
    }
   ],
   "source": [
    "train = pos_features+neg_features #pos_features[:pos_thresh]+neg_features[:neg_thresh]\n",
    "test = pos_features[pos_thresh:]+neg_features[neg_thresh:]\n",
    "\n",
    "print(\"Number of training datapoints:\", len(train))\n",
    "print(\"Number of test datapoints:\", len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the classifier:  0.7811172502791254\n"
     ]
    }
   ],
   "source": [
    "classifier = NaiveBayesClassifier.train(train)\n",
    "print(\"Accuracy of the classifier: \", nltk.classify.util.accuracy(classifier, test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "               paperback = True               -1 : 1      =   3331.1 : 1.0\n",
      "                  a-tech = True               -1 : 1      =   3043.3 : 1.0\n",
      "               hardcover = True               -1 : 1      =   1805.7 : 1.0\n",
      "                     ddr = True               -1 : 1      =   1611.3 : 1.0\n",
      "                  compaq = True               -1 : 1      =   1277.8 : 1.0\n",
      "            manufactured = True               -1 : 1      =   1118.8 : 1.0\n",
      "                   512mb = True               -1 : 1      =   1007.4 : 1.0\n",
      "                  lenovo = True               -1 : 1      =    943.6 : 1.0\n",
      "             manufacture = True               -1 : 1      =    824.6 : 1.0\n",
      "               casecrown = True               -1 : 1      =    815.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# en gros les mots qui apparaissent QUE dans les negatifs (ou QUE positifs) sont considérés comme \"informative\"\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Review: omg so great i love it !\n",
      "Predicted sentiment:  1\n",
      "Probability:  0.86\n",
      "\n",
      "Review: #blessed justin bieber\n",
      "Predicted sentiment:  1\n",
      "Probability:  0.98\n",
      "\n",
      "Review: worst thing ever just happened\n",
      "Predicted sentiment:  -1\n",
      "Probability:  0.92\n",
      "\n",
      "Review: ( (\n",
      "Predicted sentiment:  -1\n",
      "Probability:  0.93\n",
      "\n",
      "Review: is the best great love amazing justin bieber\n",
      "Predicted sentiment:  1\n",
      "Probability:  0.98\n"
     ]
    }
   ],
   "source": [
    "# test sur des inputs random\n",
    "input_reviews = [\n",
    "    \"omg so great i love it !\",\n",
    "    \"#blessed justin bieber\",\n",
    "    \"worst thing ever just happened\",\n",
    "    \"( (\",\n",
    "    \"is the best great love amazing justin bieber\"\n",
    "]\n",
    "\n",
    "for review in input_reviews:\n",
    "    print(\"\\nReview:\", review)\n",
    "    probdist = classifier.prob_classify(extract_features(review.split()))\n",
    "    pred_sentiment = probdist.max()\n",
    "    print(\"Predicted sentiment: \", pred_sentiment)\n",
    "    print(\"Probability: \", round(probdist.prob(pred_sentiment), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ids, test_data = load_data('data/test_data.txt', test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_data):\n",
    "    preds = []\n",
    "    for l in test_data:\n",
    "        preds.append(classifier.classify(extract_features(l.split())))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Id,Prediction\n",
    "# 1,-1\n",
    "# 2,1\n",
    "# 3,-1\n",
    "# ...\n",
    "with open('out/prediction_2.csv', 'w') as f:\n",
    "    f.write('Id,Prediction'+'\\n')\n",
    "    for i,p in zip(test_ids, preds):\n",
    "        f.write(i+','+p+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
