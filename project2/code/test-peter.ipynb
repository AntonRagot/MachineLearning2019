{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_tweets('../data/clean_train_full.txt', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['__label__1' if l == 1 else '__label__-1' for l in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/clean_train_full_fasttext.txt', 'w') as f:\n",
    "    for l,x in zip(labels, X):\n",
    "        f.write(l + ' ' + x + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tweets = load_tweets('../data/clean/train_full_fasttext.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def split_data(X, train_ratio, seed=None, verbose=False):\n",
    "    if seed is not None: np.random.seed(seed)\n",
    "    N = len(X)\n",
    "    limit = int(N * train_ratio)\n",
    "    indices = np.random.choice(range(N),N)\n",
    "    train_indices = indices[:limit]\n",
    "    test_indices = indices[limit:]\n",
    "    X_train = [X[i] for i in train_indices]\n",
    "    X_val = [X[i] for i in test_indices]\n",
    "    if verbose:\n",
    "        pos, neg = 0, 0\n",
    "        for x in X_train:\n",
    "            if '__label__1' in x: pos += 1\n",
    "            else: neg += 1\n",
    "        print('TRAIN %.2f%% Pos  %.2f%% Neg  (%g ratio)' % (pos/len(X_train)*100, neg/len(X_train)*100, pos/neg))\n",
    "        pos, neg = 0, 0\n",
    "        for x in X_val:\n",
    "            if '__label__1' in x: pos += 1\n",
    "            else: neg += 1\n",
    "        print('VAL   %.2f%% Pos  %.2f%% Neg (%g ratio)' % (pos/len(X_val)*100, neg/len(X_val)*100, pos/neg))\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val = split_data(all_tweets, 0.8, seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = '../data/ft_train.txt'\n",
    "save_tweets(TRAIN_PATH, X_train)\n",
    "VAL_PATH = '../data/ft_val.txt'\n",
    "save_tweets(VAL_PATH, X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "MODEL_PATH = '../models/ft.bin' # CHANGE THIS PATH\n",
    "best = fasttext.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454097, 0.8568367551426237, 0.8568367551426237)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.test(VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_all(model, test_data):\n",
    "    labels, probas = [], []\n",
    "    for x in test_data:\n",
    "        l, p = model.predict(x)\n",
    "        labels.append(int(l[0][9:]))\n",
    "        probas.append(p[0])\n",
    "    return labels, probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission('../out/submission_ft_200.csv', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1816385, 0.8567820148261519, 0.8567820148261519)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best.test(TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.1, 'epoch': 5, 'loss': 'softmax', 'wordNgrams': 3, 'dim': 200, 'minCount': 5}\n",
      "(454097, 0.8372131945377309, 0.8372131945377309)\n",
      "(454097, 0.8143414292541021, 0.8143414292541021)\n",
      "(454097, 0.8169443973424181, 0.8169443973424181)\n",
      "(454097, 0.8324058516132016, 0.8324058516132016)\n",
      "(454097, 0.8256980336800287, 0.8256980336800287)\n",
      "{'lr': 0.1, 'epoch': 5, 'loss': 'softmax', 'wordNgrams': 3, 'dim': 200, 'minCount': 0}\n",
      "(454097, 0.8369621468540862, 0.8369621468540862)\n",
      "(454097, 0.8178318729258286, 0.8178318729258286)\n",
      "(454097, 0.7235987024798667, 0.7235987024798667)\n",
      "(454097, 0.8331171533835282, 0.8331171533835282)\n",
      "(454097, 0.8265040288748879, 0.8265040288748879)\n",
      "{'lr': 0.1, 'epoch': 5, 'loss': 'ns', 'wordNgrams': 3, 'dim': 200, 'minCount': 5}\n",
      "(454097, 0.8120357544753654, 0.8120357544753654)\n",
      "(454097, 0.6906696146418057, 0.6906696146418057)\n",
      "(454097, 0.7327619429328976, 0.7327619429328976)\n",
      "(454097, 0.8007275978480368, 0.8007275978480368)\n",
      "(454097, 0.8077305069181254, 0.8077305069181254)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr' : 0.1,\n",
    "    'epoch': 5,\n",
    "    'loss' : 'softmax',\n",
    "    'wordNgrams': 3,\n",
    "    'dim' : 200,\n",
    "    'minCount' : 5\n",
    "}\n",
    "\n",
    "print(params)\n",
    "for i in range(5):\n",
    "    model = fasttext.train_supervised(TRAIN_PATH, **params)\n",
    "    print(model.test(VAL_PATH))\n",
    "\n",
    "params['minCount'] = 0\n",
    "\n",
    "print(params)\n",
    "for i in range(5):\n",
    "    model = fasttext.train_supervised(TRAIN_PATH, **params)\n",
    "    print(model.test(VAL_PATH))\n",
    "\n",
    "params['loss'] = 'ns'\n",
    "params['minCount'] = 5\n",
    "\n",
    "print(params)\n",
    "for i in range(5):\n",
    "    model = fasttext.train_supervised(TRAIN_PATH, **params)\n",
    "    print(model.test(VAL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr': 0.05, 'epoch': 5, 'loss': 'softmax', 'wordNgrams': 3, 'dim': 200, 'minCount': 5}\n",
      "(454097, 0.908658282261279, 0.908658282261279)\n",
      "(454097, 0.9091537711105777, 0.9091537711105777)\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'lr' : 0.05,\n",
    "    'epoch': 5,\n",
    "    'loss' : 'softmax',\n",
    "    'wordNgrams': 3,\n",
    "    'dim' : 200,\n",
    "    'minCount' : 5\n",
    "}\n",
    "\n",
    "TRAIN_PATH = '../data/ft_train.txt'\n",
    "VAL_PATH = '../data/ft_val.txt'\n",
    "\n",
    "print(params)\n",
    "for i in range(2):\n",
    "    X_train, X_val = split_data(all_tweets, 0.8, seed=i)\n",
    "    save_tweets(TRAIN_PATH, X_train)\n",
    "    save_tweets(VAL_PATH, X_val)\n",
    "    model = fasttext.train_supervised(TRAIN_PATH, **params)\n",
    "    print(model.test(VAL_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('../models/ft_lr005')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "TRAIN_PATH = '../data/ft_train.txt'\n",
    "VAL_PATH = '../data/ft_val.txt'\n",
    "\n",
    "params = {\n",
    "    'lr' : 0.05,\n",
    "    'epoch': 5,\n",
    "    'loss' : 'softmax',\n",
    "    'wordNgrams': 3,\n",
    "    'dim' : 200,\n",
    "    'minCount' : 5,\n",
    "    'verbose' : 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = load_tweets('../data/clean/test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Training 1 / 1"
     ]
    }
   ],
   "source": [
    "nb_iter = 1\n",
    "final_probas = np.zeros((len(test_data),))\n",
    "pos_count = np.zeros((len(test_data),))\n",
    "neg_count = np.zeros((len(test_data),))\n",
    "for i in range(nb_iter):\n",
    "    print('\\rTraining %d / %d' % (i+1, nb_iter), end='')\n",
    "    \n",
    "    # only train on part of the data for each iteration (say 80 %) ...\n",
    "    X_train, X_val = split_data(all_tweets, 0.8, seed=i)\n",
    "    save_tweets(TRAIN_PATH, X_train)\n",
    "    save_tweets(VAL_PATH, X_val)\n",
    "    model = fasttext.train_supervised(TRAIN_PATH, **params)\n",
    "    \n",
    "    # ... or train on full dataset\n",
    "    #model = fasttext.train_supervised('../data/clean/train_full_fasttext.txt', **params)\n",
    "    \n",
    "    # we can also check the accuracy on validation data (slows thigs down)\n",
    "    # print('\\r             Val acc: %g' % (model.test(VAL_PATH)[1]), end='')\n",
    "    \n",
    "    ls, ps = predict_all(model, test_data)\n",
    "    ls = np.array(ls)\n",
    "    pos_count += 1 * (ls > 0)\n",
    "    neg_count += 1 * (ls < 0)\n",
    "    final_probas += (ls * np.array(ps))\n",
    "final_probas /= nb_iter\n",
    "# final_labels = [1 if x >= 0 else -1 for x in final_probas]\n",
    "# generate_submission('../out/submission_ft_'+str(nb_iter)+'_iter.csv', final_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(454097, 0.9095721839166522, 0.9095721839166522)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.test(VAL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -0.90423965,   4.384958  ,   1.5792971 ,   2.8815448 ,\n",
       "         -5.2630014 ,   4.6238346 ,   4.801919  ,   7.2931824 ,\n",
       "         -1.8636836 ,  -6.210276  ,   6.431934  ,   0.2434191 ,\n",
       "          4.1955423 ,  -1.2406583 ,   6.889752  ,   2.1614995 ,\n",
       "         -3.30318   ,  -5.1521883 ,   3.9263895 ,  -2.5178695 ,\n",
       "         -0.4202886 ,  -0.460544  ,   3.725308  ,   3.62996   ,\n",
       "          0.48703283,   2.4030771 ,  -4.8485336 ,   9.03467   ,\n",
       "          0.83473927,  -6.803135  ,   1.6415502 , -11.539529  ,\n",
       "          2.5269089 ,   1.0341111 ,   2.4801059 ,   4.235219  ,\n",
       "          1.4422336 ,  -6.7213435 ,  -2.2742248 ,   0.36974233,\n",
       "          2.6136966 ,  -3.0076737 ,  -2.823734  ,  -0.34518144,\n",
       "          1.5038188 ,  -2.4816272 ,  -7.598887  ,  -1.1529282 ,\n",
       "         -4.3092976 ,  -4.1150093 ,   4.842186  ,  -1.8290958 ,\n",
       "         -1.8663241 ,   2.3002288 ,   3.3506458 ,  -1.799013  ,\n",
       "         -0.47564074,   7.8201127 ,   2.724961  ,   3.4218032 ,\n",
       "         -0.52700245,  -6.5371943 ,  -4.6393733 ,  -5.4852233 ,\n",
       "          2.9586868 ,   4.0344043 ,   1.4573113 ,   1.6196089 ,\n",
       "         -4.299361  ,   1.0792538 ,  -2.1667733 ,   0.6151812 ,\n",
       "         -2.7471504 ,   3.6682894 ,   3.7271097 ,  -2.1000562 ,\n",
       "         -8.16217   ,  -0.07664668,  -2.1404939 ,  -2.2769382 ,\n",
       "         -3.2294974 ,  -0.19107471,   0.56142557,   4.785972  ,\n",
       "          1.7933556 ,   4.5857496 ,  -2.3875299 ,   0.47054163,\n",
       "          1.3683083 ,   2.813354  ,   0.39514127,   6.015711  ,\n",
       "         -2.8659022 ,  -0.33196205,  -2.8124578 ,   8.471146  ,\n",
       "          0.51394373,  -5.774143  ,  -8.791063  ,  -0.17246673,\n",
       "          5.537761  ,  -0.57026815,  -0.4339017 ,   2.7860541 ,\n",
       "         -0.3653745 ,  -3.5376117 ,   2.3290288 ,   0.3629139 ,\n",
       "         -2.4558833 ,  -0.9457929 ,   1.1739997 ,  -2.3215616 ,\n",
       "          4.525342  ,   1.0737932 ,  -1.1402733 ,   5.189416  ,\n",
       "          5.7677197 ,  -0.13266909,   3.200216  ,  -0.6859559 ,\n",
       "         -2.4657934 ,  -4.7604628 ,   4.301623  ,  -0.22773087,\n",
       "          6.629582  ,  -5.1173034 ,  -0.5094113 ,   3.1984627 ,\n",
       "          2.7997925 ,   1.9682863 ,  -1.9596906 ,  -3.3881464 ,\n",
       "          2.3719676 ,  -0.96151733,   3.6472085 ,  -1.4366686 ,\n",
       "         -0.22358006,  -0.7241023 ,  -0.77073056,  -0.96960574,\n",
       "          0.13845734,  -0.6010725 ,   1.1669773 ,   3.272408  ,\n",
       "          1.6552256 ,   2.4145663 ,  -6.0714726 ,  -0.11101167,\n",
       "         -1.8489966 ,  -5.70307   ,   5.663866  ,   4.0175233 ,\n",
       "         -3.711957  ,   0.91358614,   0.63953763,   1.7853875 ,\n",
       "          3.43948   ,  -4.604183  ,  -6.9729724 ,  -1.2929827 ,\n",
       "          1.4213547 ,  -2.0271225 ,  -2.0601895 ,   3.5180593 ,\n",
       "          6.7944617 ,  -0.90300083,  -0.49914193,  -0.24374707,\n",
       "          3.9469013 ,   3.4820738 ,  -4.0827913 ,  -3.4741263 ,\n",
       "          1.359088  ,  -1.8829488 ,   0.8117214 ,  -4.121913  ,\n",
       "          0.5803686 ,  -2.4003918 ,  -6.269407  ,   1.6650788 ,\n",
       "         -4.3373027 ,  -1.3365678 ,  -6.7470655 ,  -0.3597211 ,\n",
       "         -7.1324058 ,   5.229336  ,  -1.2193491 ,  -2.1258056 ,\n",
       "          2.497938  ,   3.7425702 ,   3.2771435 ,  -1.4768122 ,\n",
       "         -3.1179461 ,  -3.3541625 ,   6.1878014 ,  -0.58610284,\n",
       "          2.1446362 ,  -2.8771732 ,   5.8664894 ,   1.4463376 ],\n",
       "       [  0.90539145,  -4.3763337 ,  -1.5769997 ,  -2.8802376 ,\n",
       "          5.2508864 ,  -4.6241674 ,  -4.794588  ,  -7.2862167 ,\n",
       "          1.8628882 ,   6.209     ,  -6.428653  ,  -0.24232042,\n",
       "         -4.1876097 ,   1.2388114 ,  -6.8765316 ,  -2.1580229 ,\n",
       "          3.297696  ,   5.147427  ,  -3.9266424 ,   2.5167103 ,\n",
       "          0.41951862,   0.46011686,  -3.721587  ,  -3.6280406 ,\n",
       "         -0.48676005,  -2.4010973 ,   4.8496394 ,  -9.035593  ,\n",
       "         -0.83509225,   6.797349  ,  -1.6407307 ,  11.544923  ,\n",
       "         -2.525351  ,  -1.0335674 ,  -2.4786649 ,  -4.2331123 ,\n",
       "         -1.4409244 ,   6.7140203 ,   2.272188  ,  -0.36925834,\n",
       "         -2.6117272 ,   3.0063188 ,   2.8211064 ,   0.34507966,\n",
       "         -1.5014882 ,   2.47762   ,   7.587403  ,   1.1501389 ,\n",
       "          4.301351  ,   4.1083627 ,  -4.834487  ,   1.8260245 ,\n",
       "          1.8637669 ,  -2.2966728 ,  -3.3467674 ,   1.7965674 ,\n",
       "          0.47533238,  -7.81646   ,  -2.7235167 ,  -3.4192276 ,\n",
       "          0.5270427 ,   6.5287104 ,   4.63416   ,   5.4793706 ,\n",
       "         -2.9581242 ,  -4.0341516 ,  -1.4562782 ,  -1.6183156 ,\n",
       "          4.2967706 ,  -1.0795679 ,   2.1651227 ,  -0.61496294,\n",
       "          2.7457442 ,  -3.6658413 ,  -3.724699  ,   2.0990746 ,\n",
       "          8.158902  ,   0.07692041,   2.138997  ,   2.2756884 ,\n",
       "          3.22796   ,   0.19101846,  -0.5611681 ,  -4.78183   ,\n",
       "         -1.7922573 ,  -4.584118  ,   2.3869655 ,  -0.47068605,\n",
       "         -1.3682054 ,  -2.81326   ,  -0.39516902,  -6.0153246 ,\n",
       "          2.8649883 ,   0.3319454 ,   2.8114161 ,  -8.470527  ,\n",
       "         -0.5141133 ,   5.7760615 ,   8.793118  ,   0.17276883,\n",
       "         -5.5398865 ,   0.5704683 ,   0.43381125,  -2.7865431 ,\n",
       "          0.36558098,   3.5407748 ,  -2.3307111 ,  -0.36321113,\n",
       "          2.4585414 ,   0.9461746 ,  -1.1745818 ,   2.3224258 ,\n",
       "         -4.5257826 ,  -1.0740238 ,   1.1403887 ,  -5.187456  ,\n",
       "         -5.767595  ,   0.13271542,  -3.2001486 ,   0.685863  ,\n",
       "          2.4661689 ,   4.7619133 ,  -4.3021016 ,   0.22775269,\n",
       "         -6.6307335 ,   5.1179924 ,   0.5098261 ,  -3.1994007 ,\n",
       "         -2.799349  ,  -1.9677994 ,   1.9586202 ,   3.3873625 ,\n",
       "         -2.370966  ,   0.96108943,  -3.6471813 ,   1.4367585 ,\n",
       "          0.22375783,   0.7237552 ,   0.77065367,   0.9696489 ,\n",
       "         -0.13822275,   0.60093147,  -1.1664922 ,  -3.2714558 ,\n",
       "         -1.6547778 ,  -2.4144979 ,   6.071072  ,   0.11077876,\n",
       "          1.8490798 ,   5.7032433 ,  -5.663898  ,  -4.0182443 ,\n",
       "          3.7133706 ,  -0.9140163 ,  -0.6397275 ,  -1.7861657 ,\n",
       "         -3.44008   ,   4.604618  ,   6.9732637 ,   1.2931457 ,\n",
       "         -1.4226353 ,   2.0280967 ,   2.0613203 ,  -3.5209572 ,\n",
       "         -6.7987957 ,   0.90336025,   0.49980548,   0.24408185,\n",
       "         -3.9475422 ,  -3.4821887 ,   4.0837483 ,   3.473846  ,\n",
       "         -1.3596289 ,   1.8833336 ,  -0.8119977 ,   4.1232085 ,\n",
       "         -0.58004016,   2.4019754 ,   6.2715364 ,  -1.6656339 ,\n",
       "          4.339928  ,   1.3370982 ,   6.7507334 ,   0.35975516,\n",
       "          7.137853  ,  -5.2334595 ,   1.2198651 ,   2.1274462 ,\n",
       "         -2.4992542 ,  -3.7443657 ,  -3.278892  ,   1.4775147 ,\n",
       "          3.1199121 ,   3.3555954 ,  -6.192011  ,   0.58648145,\n",
       "         -2.1450348 ,   2.8782778 ,  -5.8669734 ,  -1.4464257 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../out/final_probas_7_iter', final_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, ..., -1,  1, -1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "majority = pos_count > neg_count\n",
    "majority = 2 * majority - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_labels = [1 if x >= 0 else -1 for x in final_probas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(final_labels != majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission('../out/submission_ft_7_iter_majority.csv', majority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sent2vec\n",
    "import numpy\n",
    "import pickle\n",
    "model = sent2vec.Sent2vecModel()\n",
    "model.load_model('../models/embed-model-full.bin') # The model can be sent2vec or cbow-c+w-ngrams\n",
    "uni_embs, vocab = model.get_unigram_embeddings() # Return the full unigram embedding matrix\n",
    "\n",
    "#with open('full-vocab.pkl', 'wb') as f:\n",
    "#    pickle.dump(vocab, f)\n",
    "\n",
    "#numpy.save('full-vocab-matrix', uni_embs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_tweets('../data/clean_train_no_label.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42566"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42566, 700)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_embs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = dict()\n",
    "for i, w in enumerate(vocab):\n",
    "    word2vec[w] = uni_embs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {w:i for i,w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(max(X, key=lambda x: len(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_nums = np.zeros((len(X),max_len), dtype='int')\n",
    "for i,x in enumerate(X):\n",
    "    for j,w in enumerate(x.split()):\n",
    "        idx = word2index.get(w, 1)\n",
    "        X_nums[i][j] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../out/clean-train-embedded', X_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = load_tweets('../data/clean_test.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_nums = np.zeros((len(X_train),max_len), dtype='int')\n",
    "for i,x in enumerate(X_train):\n",
    "    for j,w in enumerate(x.split()):\n",
    "        idx = word2index.get(w, 1)\n",
    "        X_train_nums[i][j] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../out/clean-test-embedded', X_train_nums)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_embeddings('../out/embeddings_train.npy', '../out/clean_train_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(one_minus_one_labels_to_one_zero(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8041691942866597"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST = load_embeddings('../out/embeddings_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = one_zero_labels_to_one_minus_one(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission('../out/sub_lr.csv', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/logistic_regression.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depth = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tree = DecisionTreeClassifier(max_depth=max_depth, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=10,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=42, splitter='best')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6817404731704627"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = tree.predict(TEST)\n",
    "preds = one_zero_labels_to_one_minus_one(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission('../out/sub_dt.csv', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/decision_tree_'+str(max_depth)+'.pkl', 'wb') as f:\n",
    "    pickle.dump(tree, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* * *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/peter/.local/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = svm.predict(TEST)\n",
    "preds = one_zero_labels_to_one_minus_one(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_submission('../out/sub_svm.csv', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/svm.pkl', 'wb') as f:\n",
    "    pickle.dump(svm, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
