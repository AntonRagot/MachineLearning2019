# PLAN

- Finir de clean le data et le faire une fois pour tout (gros data set + test)
- Générer les word embeddings avec le truc donné: soit décider d'utiliser une taille fixe (200 dimensions) ou tester avec plusieurs (p.ex. 100,200,300)
- Setup google colab
- Séléctionner modèles et se les répartir: decision tree / forest, naive bayes, LSTM, GRU, logisitc regression, CNN, SVM, MLP
- Combiner meilleurs résultats pour faire un _ensemble classifier_ avec majority vote
- Se mettre d'accord sur une structure du repo
- Commencer le rapport (?)